{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Language Models\n",
    "\n",
    "A common approach for natural language tasks is to use neural networks. \n",
    "We will therefore continue to explore RNNs introduced in Section 3, training a **character RNN**, trained to predict the next character in a sentence.\n",
    "\n",
    "We follow the Char-RNN project by Andrej Karpathy (https://github.com/karpathy/char-rnn).\n",
    "We will be using his Shakespeare data to create our own Char-RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Creating the Training Dataset\n",
    "\n",
    "Let's download the Shakespeare dataset and take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Download the Shakespeare dataset\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()\n",
    "\n",
    "# Shows a short text sample\n",
    "print(shakespeare_text[:420])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to our model will be a the beginning of a Shakespeare sonnet (i.e. a sequence of characters).\n",
    "Given this sequence of characters, we want our model to predict the next character.\n",
    "For simplicity, we will only use **lowercase** characters.\n",
    "\n",
    "Given `shakespeare_text` is our dataset, create the following variables:\n",
    "- `vocab`, which is a string of all lowercase characters that appear in `shakespeare_text`\n",
    "- `vocab_size`, which is the number of distinct characters in `shakespeare_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary: \n",
      " !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\n",
      "Number of distinct characters: 39\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "vocab = \"\".join(sorted(set(shakespeare_text.lower())))\n",
    "vocab_size = len(set(shakespeare_text.lower()))\n",
    "\n",
    "\n",
    "# Code you don't worry about\n",
    "print(\"Our vocabulary: \" + vocab)\n",
    "print(\"Number of distinct characters: \" + str(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must encode every character as an integer because the input to a neural network must be numerical. \n",
    "\n",
    "It's easiest to do this using `keras.layers.TextVectorization` layer to encode this text (i.e. convert it from characters to integer IDs).\n",
    "This layer turns raw strings into an encoded representation that can be read by neural network layers.\n",
    "We set `split=\"character\"` to get character-level encoding rather than the default word-level encoding, and we use `standardize=\"lower\"` to convert the text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tf.keras.layers.TextVectorization to create a text_vec_layer object. \n",
    "# Set the split parameter to \"character\" and standardize parameter to \"lower\".\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
    "                                                   standardize=\"lower\")\n",
    "\n",
    "# Call the adapt() method on text_vec_layer passing in a list of one item, shakespeare_text.\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "\n",
    "# Use text_vec_layer on shakespeare_text (as list of one item) to obtain encoded\n",
    "# character ID sequences.\n",
    "# Save the first list element of this result to a variable called encoded\n",
    "encoded = text_vec_layer([shakespeare_text])[0]\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each character is now mapped to an integer, starting at 2. The `TextVectorization` layer reserved the value 0 for padding tokens, and it reserved 1 for unknown characters.\n",
    "We won’t need either of these tokens for now because neither are in the vocabulary, so we won't be using them to write our sonnets either.\n",
    "(When have you seen Shakespeare make up unknown characters? That's why.)\n",
    "\n",
    "Let’s subtract 2 from the character IDs and compute the number of distinct characters and the total number of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  1115394\n",
      "Number of tokens:  39\n"
     ]
    }
   ],
   "source": [
    "# Drop tokens 0 (pad) and 1 (unknown) by subtracting 2 from the character IDs\n",
    "# stored in variable encoded\n",
    "# (They were not in original vocabulary anyway)\n",
    "encoded -= 2\n",
    "\n",
    "# Compute the number of distinct characters n_tokens using vocabulary_size()\n",
    "# method of text_vec_layer\n",
    "# Remember: we are removing 2 \n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2\n",
    "\n",
    "# Compute the total number of characters \n",
    "dataset_size = len(encoded)\n",
    "\n",
    "\n",
    "# Code you don't worry about \n",
    "print(\"Dataset size: \", dataset_size)\n",
    "print(\"Number of tokens: \", n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a sequence-to-sequence RNN, we can convert this long sequence into input/target pairs. This dataset creation involves dividing the data into windows of a fixed size. For instance, a dataset sequence of the text \"to be or not to b\" will be turned into input as \"to be or not to\" sequence and target as \"o be or not to be\" sequence. This target sequence indicates that for a given input sequence, the next character should be \"e\". The model can then be trained on these input/target pairs to learn the underlying patterns in the text and generate more text of a similar style. \n",
    "\n",
    "The function `to_dataset` will convert our long sequence of character IDs (encoded text) into a dataset of input/target window pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "\n",
    "    # Prepare dataset of character IDs to be processed by tensorflow.\n",
    "    # Use tf.data.Dataset.from_tensor_slices and pass in sequence as argument\n",
    "    # and store as variable ds.\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "\n",
    "    # Create windows of size length + 1.\n",
    "    # Call the window() method on ds, setting the size parameter to length+1,\n",
    "    # the shift parameter to 1, drop_remainder parameter to True.\n",
    "    # Save the result in variable ds.\n",
    "    ds = ds.window(size=length + 1, shift=1, drop_remainder=True)\n",
    "    \n",
    "    # Don't worry about this\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
    "\n",
    "    # If the shuffle is set to True, update variable ds by calling shuffle()\n",
    "    # method on it with parameter buffer_size set to 100_000 and seed parameter\n",
    "    # set to seed\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
    "\n",
    "    # Batch the resulting dataset. \n",
    "    # Update the ds variable by calling the batch() method on ds with parameter \n",
    "    # batch_size=batch_size\n",
    "    ds = ds.batch(batch_size=batch_size)\n",
    "\n",
    "    # Create input/output sequences by taking first *length* characters as input\n",
    "    # and last *length* characters as output.\n",
    "    # Do this by using the map() method on ds, and use the lambda function to \n",
    "    # create a tuple with the first length characters as the first element\n",
    "    # and the last length characters as the second element\n",
    "    ds = ds.map(lambda window: (window[:, :-1], window[:, 1:]))\n",
    "    \n",
    "    # Don't worry about this\n",
    "    return ds.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This diagram illustrates what `to_dataset` is doing:\n",
    "\n",
    "<img src=\"to_dataset.png\" width=\"500\" style=\"display: block; margin: 0 auto\">\n",
    "\n",
    "Batching is a technique used to divide large datasets into smaller subsets or batches.\n",
    "Instead of feeding the entire dataset (of our input/output pairs of windows) to the model at once, we divide it into batches, which are fed to the model one-by-one during training.\n",
    "Each batch is processed independently, and the model updates its weights after processing each batch.\n",
    "Batching makes training more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 4,  5,  2, 23]])>,\n",
       "  <tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 5,  2, 23,  3]])>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example using to_dataset()\n",
    "# This code creates a dataset with a single training example: an input/output pair\n",
    "# The input represents \"to b\" and the output represents \"o be\", so the model \n",
    "# should learn to predict the next character, i.e., \"e\"\n",
    "list(to_dataset(text_vec_layer([\"To be\"])[0], length=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the entire dataset is 1,115,394 characters long and we have limited time, we will use a smaller portion of the dataset to make sure we can finish training during this workshop.\n",
    "We will split it up so we use roughly 90% for training, 5% for validation and the remaining 5% for testing.\n",
    "\n",
    "We initially specified the window length as 100, but it is worth experimenting with different window lengths.\n",
    "While shorter lengths make it easier and quicker to train the RNN, as the RNN is not able to learn any pattern that is longer than the specified length, it is important to avoid choosing a window length that is too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about this code\n",
    "length = 100\n",
    "subset_proportion = 0.5\n",
    "\n",
    "# Create variable reduced_dataset_size that calculates the size of the dataset\n",
    "# we will be using in training using dataset_size and subset_proportion.\n",
    "# Your result should be an integer.\n",
    "reduced_dataset_size = int(dataset_size * subset_proportion)\n",
    "\n",
    "# Slice the encoded data into training, validation, and test sets by the following proportions:\n",
    "# - 90% for training (train_encoded)\n",
    "# - 5% for validation (validation_encoded)\n",
    "# - 5% for testing (test_encoded)\n",
    "\n",
    "# The following code slices encoded data as per the above specifications.\n",
    "\n",
    "# Slice the first 90% of data for training using integer indexing\n",
    "train_encoded = encoded[:int(reduced_dataset_size * 0.9)]\n",
    "\n",
    "# Slice the next 5% of data for validation\n",
    "validation_encoded = encoded[int(reduced_dataset_size * 0.9):int(reduced_dataset_size * 0.95)]\n",
    "\n",
    "# Slice the last 5% of data for testing\n",
    "test_encoded = encoded[int(reduced_dataset_size * 0.95):reduced_dataset_size]\n",
    "\n",
    "# Set a random seed (42) for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Use the function to_dataset() to create training, validation, and test sets\n",
    "# by calling the function with the corresponding slicing of the encoded data\n",
    "\n",
    "# Call the function to create a training set with the following specifications:\n",
    "# - Pass in train_encoded as the sequence parameter\n",
    "# - Set length of the window to 100 using length parameter\n",
    "# - Set shuffle parameter to True to shuffle the data\n",
    "# - Set seed to 42 for reproducibility\n",
    "train_set = to_dataset(train_encoded, length=length, shuffle=True, seed=42)\n",
    "\n",
    "# Call the function to create a validation set with the following specifications:\n",
    "# - Pass in validation_encoded as the sequence parameter\n",
    "# - Set length of the window to 100 using length parameter\n",
    "valid_set = to_dataset(validation_encoded, length=length)\n",
    "\n",
    "# Call the function to create a test set with the following specifications:\n",
    "# - Pass in test_encoded as the sequence parameter\n",
    "# - Set length of the window to 100 using length parameter\n",
    "test_set = to_dataset(test_encoded, length=length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training the Char-RNN Model\n",
    "\n",
    "**Warning**: the following code may one or two hours to run, depending on your GPU. Without a GPU, it may take over 24 hours. If you don't want to wait, just skip the next two code cells and run the code below to download a pretrained model.\n",
    "\n",
    "To make GPU work, in terminal: `python -m pip install tensorflow-metal`\n",
    "\n",
    "**Note**: the `GRU` class will only use cuDNN acceleration (assuming you have a GPU) when using the default values for the following arguments: `activation`, `recurrent_activation`, `recurrent_dropout`, `unroll`, `use_bias` and `reset_after`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset is reasonably large, and modeling language is quite a difficult task, we need more than a simple RNN with a few recurrent neurons.\n",
    "Let’s build and train a model with one GRU layer composed of 128 units (you can try tweaking the number of layers and units later, if needed).\n",
    "\n",
    "Let’s go over this code:\n",
    "\n",
    "- This model does not handle text preprocessing, so let’s wrap it in a final model containing the `tf.keras.layers.TextVectorization` layer as the first layer, plus a `tf.keras.layers.Lambda` layer to subtract 2 from the character IDs (since we’re not using the padding and unknown tokens for now):\n",
    "\n",
    "- We use an `Embedding` layer as the first layer, to encode the character IDs (embeddings were introduced in Chapter 13). The `Embedding` layer’s number of input dimensions is the number of distinct character IDs, and the number of output dimensions is a hyperparameter you can tune—we’ll set it to 16 for now. Whereas the inputs of the `Embedding` layer will be 2D tensors of shape *[batch size, window length]*, the output of the Embedding layer will be a 3D tensor of shape *[batch size, window length, embedding size]*.\n",
    "\n",
    "- We use a `Dense` layer for the output layer: it must have 39 units (n_tokens) because there are 39 distinct characters in the text, and we want to output a probability for each possible character (at each time step). The 39 output probabilities should sum up to 1 at each time step, so we apply the softmax activation function to the outputs of the Dense layer.\n",
    "\n",
    "- Lastly, we compile this model, using the `\"sparse_categorical_crossentropy\"` loss and a Nadam optimizer, and we train the model for several epochs, using a `ModelCheckpoint` callback to save the best model (in terms of validation accuracy) as training progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "    266/Unknown - 21s 46ms/step - loss: 2.8339 - accuracy: 0.2172"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 31\u001b[0m\n\u001b[1;32m     22\u001b[0m model_ckpt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     23\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_shakespeare_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Train the model using the fit() method. Pass the training and validation sets \u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# to the train_set and valid_set parameters, respectively. \u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Also, set the number of epochs to a number between 3 and 5 and the callback\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# parameter to a list with only one element: model_ckpt\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_ckpt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/GitHub/kai-edc2024-workshop/edc2024/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)  \n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Call the compile method on model, setting these parameters:\n",
    "# - loss as \"sparse_categorical_crossentropy\"\n",
    "# - optimiser as \"nadam\"\n",
    "# - metrics as a single-element list containing only \"accuracy\"\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# A callback is a set of functions that can be applied during training to \n",
    "# perform various tasks, such as saving the best model weights, early stopping \n",
    "# if the validation loss stops improving, etc.\n",
    "# Use tf.keras.callbacks.ModelCheckpoint to create a model_ckpt object. \n",
    "# Set the filepath parameter to \"my_shakespeare_model\", monitor parameter to\n",
    "# \"val_accuracy\" and save_best_only parameter to True.\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"my_shakespeare_model\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True)\n",
    "\n",
    "# Train the model using the fit() method. Pass the training and validation sets \n",
    "# to the train_set and valid_set parameters, respectively. \n",
    "# Also, set the number of epochs to a number between 3 and 5 and the callback\n",
    "# parameter to a list with only one element: model_ckpt\n",
    "history = model.fit(train_set,\n",
    "                    validation_data=valid_set,\n",
    "                    epochs=5,\n",
    "                    callbacks=[model_ckpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does not handle text preprocessing, so let’s wrap it in a final model containing the `tf.keras.layers.TextVectorization` layer as the first layer, plus a `tf.keras.layers.Lambda` layer to subtract 2 from the character IDs (since we’re not using the padding and unknown tokens for now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m shakespeare_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      2\u001b[0m     text_vec_layer,\n\u001b[1;32m      3\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m X: X \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m),  \u001b[38;5;66;03m# no <PAD> or <UNK> tokens\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\n\u001b[1;32m      5\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
    "    model\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since model training takes a long time, we have a pretrained model for you.\n",
    "The following code will download it.\n",
    "Uncomment the last line if you want to use it instead of the model trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Downloads a pretrained model\n",
    "with tf.device('/CPU:0'):\n",
    "    url = \"https://github.com/ageron/data/raw/main/shakespeare_model.tgz\"\n",
    "    path = tf.keras.utils.get_file(\"shakespeare_model.tgz\", url, extract=True) \n",
    "    model_path = Path(path).with_name(\"shakespeare_model\")\n",
    "    model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use it to predict the next character in the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the predict method on [\"To be or not to b\"]\n",
    "y_prob = model.predict([\"To be or not to b\"])[0, -1]\n",
    "y_pred = tf.argmax(y_prob)  # choose the most probable character ID\n",
    "text_vec_layer.get_vocabulary()[y_pred + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.81564450e-01, 6.64177760e-02, 6.29598182e-03, 1.06545657e-01,\n",
       "         2.56400798e-02, 7.74683431e-02, 3.66694391e-01, 4.69605159e-03,\n",
       "         3.51578929e-02, 1.17589252e-05, 9.23981052e-03, 1.84964873e-02,\n",
       "         5.56145835e-07, 1.79435220e-02, 2.96746817e-04, 6.57378184e-03,\n",
       "         1.29411556e-02, 2.60792151e-02, 1.12853933e-03, 9.53491326e-05,\n",
       "         1.11382190e-06, 1.23063379e-04, 1.17037701e-03, 9.44408122e-03,\n",
       "         2.98097063e-07, 3.17247171e-08, 1.23338075e-02, 5.36633609e-03,\n",
       "         1.70396885e-03, 3.56346532e-03, 1.34389929e-03, 1.66126771e-03,\n",
       "         5.96528821e-07, 1.22643662e-09, 1.27850730e-09, 1.44478562e-07,\n",
       "         6.61337929e-10, 4.58128244e-19, 9.39734246e-09],\n",
       "        [7.48782039e-01, 8.53534402e-06, 1.50150236e-05, 1.44324629e-02,\n",
       "         8.39594213e-06, 7.65351113e-04, 2.05993318e-04, 6.82524813e-04,\n",
       "         7.88733065e-02, 2.04552170e-02, 1.16905849e-02, 1.67817920e-02,\n",
       "         1.00985453e-05, 1.16155930e-02, 1.32352859e-02, 9.40741316e-08,\n",
       "         1.40420198e-02, 1.63870957e-02, 4.55428293e-04, 1.57159258e-04,\n",
       "         1.22141908e-03, 3.30902496e-03, 3.66415043e-04, 1.35832736e-02,\n",
       "         3.87550244e-06, 2.48537685e-06, 7.70108355e-03, 1.02849379e-02,\n",
       "         1.89475529e-03, 2.11326755e-03, 3.32344323e-04, 1.04701472e-02,\n",
       "         1.28609043e-08, 2.43635245e-08, 1.08163236e-04, 4.82918404e-06,\n",
       "         1.49594269e-12, 1.90485510e-20, 1.42422105e-16],\n",
       "        [1.41632854e-05, 7.60131003e-03, 1.24783091e-01, 1.04637602e-02,\n",
       "         6.27921075e-02, 3.76664996e-02, 6.60940930e-02, 7.14722499e-02,\n",
       "         7.07934052e-03, 6.69006957e-03, 3.41560190e-06, 2.33795103e-02,\n",
       "         6.96958229e-02, 1.09784612e-02, 1.20131195e-01, 1.51825165e-02,\n",
       "         6.15265332e-02, 1.24427770e-05, 6.80199564e-02, 3.41177359e-02,\n",
       "         3.18163931e-02, 6.71968907e-02, 7.17041045e-02, 3.30159514e-06,\n",
       "         1.85537953e-02, 1.68983242e-03, 4.28117119e-06, 1.29902945e-03,\n",
       "         5.99755822e-06, 1.52753853e-06, 3.92893116e-06, 1.05586478e-05,\n",
       "         6.72447355e-03, 3.25351185e-03, 2.24984942e-05, 5.71280043e-06,\n",
       "         2.45354154e-10, 5.50654459e-14, 2.18985045e-18],\n",
       "        [2.72154784e-06, 7.30625093e-01, 3.12322896e-08, 2.32346114e-02,\n",
       "         4.75784466e-02, 2.50117276e-02, 5.87861360e-09, 2.85200940e-07,\n",
       "         8.31194967e-02, 2.80776527e-04, 1.25573054e-08, 1.98386405e-02,\n",
       "         2.55295274e-09, 5.36179952e-02, 5.75829006e-07, 1.66847780e-02,\n",
       "         2.08140455e-06, 1.34895402e-07, 6.21055082e-11, 7.63254093e-07,\n",
       "         5.53494972e-10, 2.72109503e-07, 2.39209141e-09, 1.78324810e-09,\n",
       "         3.10659599e-14, 3.44951324e-11, 2.25699566e-08, 8.11461462e-07,\n",
       "         1.87369631e-09, 3.01398906e-09, 1.91888705e-09, 1.31767649e-07,\n",
       "         1.45303986e-07, 3.33612746e-07, 1.03738600e-08, 8.24142259e-21,\n",
       "         1.52227254e-21, 2.32667764e-27, 2.05264560e-14],\n",
       "        [5.60202718e-01, 1.11718876e-02, 1.56691838e-02, 5.07335608e-05,\n",
       "         1.43966392e-01, 2.29187645e-02, 3.45591344e-02, 3.05639710e-02,\n",
       "         1.00730523e-03, 2.91143358e-03, 5.79012418e-03, 1.87484119e-02,\n",
       "         4.94004712e-02, 9.99878466e-07, 4.66668207e-05, 1.18304754e-03,\n",
       "         6.99336058e-04, 2.09086947e-02, 2.69824695e-02, 2.08732509e-03,\n",
       "         3.06260176e-02, 2.14320942e-04, 3.00447713e-03, 1.19566731e-03,\n",
       "         7.42838902e-09, 7.48778039e-05, 4.81795100e-03, 1.51469151e-03,\n",
       "         3.10715102e-03, 4.40785242e-03, 1.38521835e-03, 7.48460705e-04,\n",
       "         3.81448899e-06, 2.14684442e-05, 8.74039961e-06, 1.97123740e-07,\n",
       "         5.38991372e-20, 4.44587061e-26, 8.38045397e-26],\n",
       "        [1.88721276e-06, 1.40965870e-02, 1.48173764e-01, 1.19736707e-02,\n",
       "         1.18105978e-01, 4.18807305e-02, 6.50071874e-02, 8.54815990e-02,\n",
       "         2.23224778e-02, 3.66313420e-02, 3.13653459e-06, 2.10410058e-02,\n",
       "         3.48397382e-02, 5.46954386e-03, 6.58012033e-02, 5.64956553e-02,\n",
       "         3.52163278e-02, 1.38744076e-06, 5.20047806e-02, 3.48852500e-02,\n",
       "         3.46527137e-02, 4.53492329e-02, 4.36429493e-02, 4.36967730e-06,\n",
       "         1.00723794e-02, 8.76615196e-03, 9.87254680e-07, 1.27569237e-03,\n",
       "         6.42096722e-07, 3.60768041e-07, 4.80763333e-07, 3.03513502e-06,\n",
       "         5.51010389e-03, 1.28630351e-03, 6.96556128e-07, 6.46823594e-07,\n",
       "         7.32909653e-12, 2.05899005e-13, 6.24924716e-19],\n",
       "        [1.92457996e-03, 4.39804886e-03, 3.20079252e-02, 1.71841632e-04,\n",
       "         6.95480453e-03, 3.57783283e-05, 1.76614940e-05, 3.80236452e-04,\n",
       "         1.10535674e-01, 2.76781112e-01, 1.84917080e-05, 1.78805329e-02,\n",
       "         6.92889793e-03, 2.17751101e-01, 1.58313906e-03, 1.41074770e-05,\n",
       "         9.55487788e-03, 1.09353079e-03, 4.12383955e-03, 2.01670036e-01,\n",
       "         1.42495619e-05, 2.66049001e-02, 7.20125251e-03, 1.01427322e-05,\n",
       "         8.24108952e-07, 2.31150296e-02, 1.34349073e-04, 4.43933122e-02,\n",
       "         5.77548008e-06, 5.54553699e-05, 4.19956359e-06, 2.15157561e-04,\n",
       "         5.03826527e-08, 2.04740372e-05, 4.39738389e-03, 1.22295421e-06,\n",
       "         5.07062066e-11, 2.12593091e-23, 1.42459514e-12],\n",
       "        [2.57803738e-01, 2.46581808e-03, 2.12698430e-02, 3.14074378e-10,\n",
       "         1.54956840e-02, 1.26791696e-04, 1.35530954e-07, 4.25117789e-03,\n",
       "         1.60463946e-03, 1.14711607e-02, 6.06998289e-03, 2.44582053e-02,\n",
       "         6.35630310e-01, 1.74161002e-07, 2.35291118e-05, 5.21297761e-09,\n",
       "         1.64000612e-05, 2.25192704e-03, 1.99806504e-03, 1.86375820e-03,\n",
       "         8.68495335e-05, 9.76104548e-06, 9.30767506e-03, 2.98484083e-04,\n",
       "         2.97942461e-04, 2.91710439e-05, 1.40405190e-03, 1.53301400e-04,\n",
       "         8.13937688e-04, 3.76665092e-04, 1.30880013e-04, 2.55128194e-04,\n",
       "         1.93716915e-07, 3.45041808e-05, 1.51143507e-11, 4.37752362e-10,\n",
       "         4.27059321e-17, 2.26125925e-19, 2.10059548e-21],\n",
       "        [7.35740696e-06, 3.34044956e-02, 1.90624550e-01, 7.09976861e-03,\n",
       "         2.60431264e-02, 2.90658306e-02, 1.41460355e-02, 6.65530041e-02,\n",
       "         3.32317390e-02, 2.14642406e-01, 2.34411818e-05, 3.89536582e-02,\n",
       "         1.35171721e-02, 1.73968641e-04, 4.31696773e-02, 4.99024615e-03,\n",
       "         6.92024902e-02, 3.31981573e-06, 4.04456444e-02, 3.09233498e-02,\n",
       "         5.50671387e-03, 8.74835253e-02, 3.72320712e-02, 4.77556341e-06,\n",
       "         1.68949633e-03, 2.38182768e-03, 3.15683701e-06, 5.14319981e-04,\n",
       "         1.27910141e-06, 8.64250978e-07, 6.43481769e-07, 1.06937659e-06,\n",
       "         8.32978543e-03, 6.18040678e-04, 6.41101451e-07, 1.05881209e-05,\n",
       "         5.08228485e-12, 9.26932576e-13, 3.72517073e-20],\n",
       "        [1.88172880e-10, 9.05693546e-02, 1.40687755e-08, 8.59257936e-01,\n",
       "         1.80026535e-02, 1.37300249e-02, 4.34207686e-06, 4.11931470e-12,\n",
       "         2.72167426e-07, 1.68458229e-07, 1.07891578e-10, 1.54955117e-07,\n",
       "         4.68762025e-08, 1.75678693e-02, 2.60520352e-07, 2.24949031e-06,\n",
       "         3.82035660e-06, 2.68400996e-11, 6.75738149e-04, 2.43939894e-06,\n",
       "         2.67439589e-07, 3.48224845e-08, 1.00974731e-08, 1.15234070e-12,\n",
       "         6.59259513e-07, 1.57508606e-04, 4.23726288e-12, 2.16220997e-08,\n",
       "         1.05715295e-12, 4.46547356e-12, 2.25044769e-13, 4.15837503e-12,\n",
       "         1.29543629e-08, 2.15945201e-05, 2.45901219e-06, 1.79445727e-12,\n",
       "         9.65266732e-19, 1.97686832e-12, 1.61122677e-21],\n",
       "        [1.58293605e-01, 1.04222105e-04, 5.33985257e-01, 1.40323100e-04,\n",
       "         1.78278438e-04, 5.33383666e-03, 1.45400563e-07, 8.58539436e-03,\n",
       "         2.35174205e-02, 7.41600245e-02, 1.37335761e-02, 1.61318632e-04,\n",
       "         1.83813635e-03, 2.38663051e-03, 8.25999377e-05, 2.28061705e-04,\n",
       "         9.06644985e-02, 3.60549008e-03, 6.64120074e-04, 4.59348055e-04,\n",
       "         1.82281001e-05, 6.17046729e-02, 2.52083322e-04, 1.48701586e-03,\n",
       "         3.19131250e-05, 4.52662993e-04, 5.09409374e-03, 3.86776286e-04,\n",
       "         5.17345034e-03, 6.41929125e-03, 5.40396104e-05, 6.94909482e-04,\n",
       "         3.14517069e-06, 3.68353517e-06, 1.85557724e-07, 1.01565172e-04,\n",
       "         1.16225453e-10, 3.04514884e-14, 1.74849148e-18],\n",
       "        [7.66933441e-01, 4.34516603e-03, 6.61389495e-05, 4.08260268e-04,\n",
       "         1.43223544e-04, 1.29511137e-03, 5.54457195e-02, 1.86481717e-04,\n",
       "         2.55599116e-06, 1.58530456e-05, 8.54146481e-02, 1.74992325e-04,\n",
       "         2.82609632e-04, 4.73438675e-04, 8.82216864e-06, 9.35263600e-08,\n",
       "         2.25399839e-04, 2.60936841e-02, 1.13426184e-03, 2.90157695e-05,\n",
       "         1.72068297e-08, 1.10713734e-06, 1.43064142e-07, 9.60936770e-03,\n",
       "         1.16685135e-06, 1.59692138e-11, 2.59643905e-02, 3.11259821e-04,\n",
       "         8.38700496e-03, 9.34743043e-03, 2.17941683e-03, 1.51985022e-03,\n",
       "         1.04705355e-10, 1.00136477e-09, 4.21948254e-09, 2.86262991e-09,\n",
       "         8.73143754e-15, 2.51441503e-18, 1.58430242e-20],\n",
       "        [3.99001829e-06, 5.54041611e-03, 9.39329416e-02, 8.35208744e-02,\n",
       "         8.98307487e-02, 5.61597236e-02, 5.86719662e-02, 1.32918835e-01,\n",
       "         2.33148597e-02, 1.30621158e-02, 2.77840736e-05, 1.98317524e-02,\n",
       "         5.20344898e-02, 7.82904401e-03, 6.51701540e-02, 2.84400452e-02,\n",
       "         5.79364002e-02, 5.20258027e-06, 1.86165925e-02, 4.40454967e-02,\n",
       "         2.13484373e-02, 7.74504319e-02, 2.91790180e-02, 1.52459479e-05,\n",
       "         5.96052781e-03, 5.30668255e-03, 4.88416163e-06, 1.54381734e-03,\n",
       "         3.12210932e-06, 1.48427023e-06, 2.45441197e-06, 1.38693667e-05,\n",
       "         6.93563139e-03, 1.33474881e-03, 5.32015838e-06, 8.36099673e-07,\n",
       "         6.06801109e-10, 3.29247870e-12, 2.94797410e-18],\n",
       "        [2.89977792e-10, 2.21833903e-02, 1.04529292e-08, 3.62762630e-01,\n",
       "         3.27282250e-02, 2.12779045e-02, 5.09798706e-01, 2.75988607e-11,\n",
       "         2.89998595e-02, 9.57090518e-10, 2.39459619e-10, 6.23325832e-07,\n",
       "         6.60083797e-15, 7.84491468e-03, 8.57092246e-08, 1.16157625e-03,\n",
       "         1.32415583e-02, 1.12683385e-09, 1.92062600e-07, 1.27692132e-07,\n",
       "         3.48414145e-11, 9.19940675e-08, 4.26243005e-08, 3.14033105e-11,\n",
       "         2.39812684e-12, 2.12167740e-13, 3.06239617e-10, 7.32072292e-10,\n",
       "         2.23978631e-11, 6.52134943e-11, 3.58062989e-11, 5.81249007e-11,\n",
       "         7.95501304e-11, 1.64689703e-11, 6.29466694e-13, 1.19852140e-11,\n",
       "         2.84271603e-13, 2.18484146e-18, 1.09753935e-10],\n",
       "        [6.18130684e-01, 8.34062696e-04, 1.66022641e-04, 2.29476765e-01,\n",
       "         4.98413166e-04, 1.94899493e-03, 6.96094357e-04, 3.29070492e-04,\n",
       "         2.96422280e-03, 9.29279812e-03, 1.96181089e-02, 1.87819246e-02,\n",
       "         1.99146045e-04, 3.16592157e-02, 5.23248641e-03, 4.25655981e-06,\n",
       "         8.74234363e-03, 1.47329026e-03, 1.68724466e-04, 7.91728380e-05,\n",
       "         9.71515663e-03, 3.74037540e-04, 5.76255610e-04, 3.16024409e-04,\n",
       "         3.29657254e-04, 1.94573090e-06, 8.88511131e-04, 6.50126720e-03,\n",
       "         4.76207933e-04, 6.37493737e-04, 1.19553051e-05, 2.96345837e-02,\n",
       "         6.43636672e-11, 3.97792337e-06, 2.36481632e-04, 6.18134663e-07,\n",
       "         3.19904953e-12, 4.51949898e-22, 2.62222417e-18],\n",
       "        [1.70072144e-05, 2.18841787e-02, 1.86436072e-01, 1.30240256e-02,\n",
       "         5.50541244e-02, 6.94002397e-03, 9.79071558e-02, 9.69740003e-02,\n",
       "         1.93819068e-02, 4.49746475e-03, 9.13802942e-05, 2.49921475e-02,\n",
       "         3.51304226e-02, 1.70543324e-02, 7.25229904e-02, 4.79798578e-02,\n",
       "         2.26426739e-02, 3.70868911e-05, 6.26318753e-02, 1.93237737e-02,\n",
       "         1.36419823e-02, 8.95826817e-02, 5.81495911e-02, 1.56025908e-05,\n",
       "         1.50814932e-02, 3.99041595e-03, 3.38314021e-05, 1.14731619e-03,\n",
       "         2.68912481e-05, 7.02170155e-06, 3.12455159e-05, 1.43084044e-05,\n",
       "         6.56793220e-03, 7.02578155e-03, 1.46338483e-04, 1.51225495e-05,\n",
       "         8.55016502e-10, 1.61427776e-14, 1.42441441e-16],\n",
       "        [2.62803184e-07, 8.46599162e-01, 3.86034937e-09, 8.14233255e-03,\n",
       "         4.25275005e-02, 1.99384168e-02, 1.72885706e-09, 1.05552886e-07,\n",
       "         4.21643257e-02, 5.01868453e-05, 3.98378077e-08, 1.20775625e-02,\n",
       "         7.48878293e-10, 2.40257215e-02, 1.22273832e-07, 4.47269762e-03,\n",
       "         7.88819818e-07, 5.85964983e-08, 3.93116407e-11, 1.68770214e-07,\n",
       "         1.02234395e-10, 1.17807907e-07, 1.17004872e-09, 1.69419290e-09,\n",
       "         1.78766964e-14, 6.97031408e-12, 2.04375521e-08, 1.45089984e-07,\n",
       "         1.35860112e-09, 2.69559020e-09, 1.38071221e-09, 3.50191414e-08,\n",
       "         4.10211776e-08, 1.81903943e-07, 1.64992309e-09, 2.30294030e-20,\n",
       "         1.44913125e-20, 4.53927898e-27, 3.76948364e-14]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([\"To be or not to b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! Our model made the correct prediction!\n",
    "It is now ready to write full sonnets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Fake Shakespearean Text\n",
    "\n",
    "Wee issue here: we cannot set tensorflow to use GPU for training and using the model. The output is poo-poo. CPU output is good. DILEMMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate new text using the char-RNN model, we could feed it some text, make the model predict the most likely next letter, add it to the end of the text, then give the extended text to the model to guess the next letter, and so on. This is called greedy decoding. But in practice this often leads to the same words being repeated over and over again. Instead, we can sample the next character randomly, with a probability equal to the estimated probability, using TensorFlow’s tf.random.categorical() function. This will generate more diverse and interesting text. The categorical() function samples random class indices, given the class log probabilities (logits). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[0, 1, 0, 2, 1, 0, 0, 1]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probas = tf.math.log([[0.5, 0.4, 0.1]])  # probas = 50%, 40%, and 10%\n",
    "tf.random.categorical(log_probas, num_samples=8)  # draw 8 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have more control over the diversity of the generated text, we can divide the logits by a number called the temperature, which we can tweak as we wish. A temperature close to zero favors high-probability characters, while a high temperature gives all characters an equal probability. Lower temperatures are typically preferred when generating fairly rigid and precise text, such as mathematical equations, while higher temperatures are preferred when generating more diverse and creative text. The following next_char() custom helper function uses this approach to pick the next character to add to the input text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "\n",
    "    # Generate the predicted probabilities for the next character in the sequence\n",
    "    # based on the current text\n",
    "    # Select the final output vector from this prediction, i.e. the last character in the sequence\n",
    "    y_proba = model.predict([text])[0, -1:]\n",
    "    \n",
    "    # Rescale the probability distribution using the temperature parameter\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "\n",
    "    # Sample the next character ID from this rescaled distribution\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n",
    "\n",
    "    # Return the character corresponding to the sampled ID\n",
    "    return text_vec_layer.get_vocabulary()[char_id + 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can write another small helper function that will repeatedly call `next_char()` to get the next character and append it to the given text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "To be or not to be the duke\n",
      "as it is a proper strange death,\n",
      "and the\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "print(extend_text(\"To be or not to be\", temperature=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "To be or not to be edward knows\n",
      "whose stew, am i bid them for you, g\n"
     ]
    }
   ],
   "source": [
    "print(extend_text(\"To be or not to be\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "To be or not to bed tire\n",
      "the strangeness pity. what is't your allay,\n"
     ]
    }
   ],
   "source": [
    "print(extend_text(\"To be or not to be\", temperature=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edc2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
